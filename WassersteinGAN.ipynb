{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/essegibi/isml/blob/main/WassersteinGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e399db56",
      "metadata": {
        "id": "e399db56"
      },
      "source": [
        "# Generative Adversial Networks\n",
        "\n",
        "GANs mostly differ in their loss function, while similar in their basic construction [^1]\n",
        "\n",
        "## Introduction\n",
        "\n",
        "The compute_gradient_penalty function is used to calculate the gradient penalty loss for the Wasserstein GAN (Generative Adversarial Network) with gradient penalty. This loss term is added to the generator and discriminator loss functions to improve the stability and convergence of the GAN training process.\n",
        "\n",
        "## Key Concepts\n",
        "\n",
        "Before diving into the code, let's understand some key concepts related to the Wasserstein GAN and gradient penalty:\n",
        "\n",
        "### Wasserstein GAN:\n",
        "\n",
        "The Wasserstein GAN is a variant of the traditional GAN that uses the Wasserstein distance (also known as Earth Mover's distance) as a measure of similarity between the real and generated samples. It aims to minimize the distance between the distributions of real and generated samples, leading to more stable and meaningful training.\n",
        "\n",
        "### Gradient Penalty:\n",
        "\n",
        "The gradient penalty is a regularization technique used in the Wasserstein GAN to enforce the Lipschitz constraint on the discriminator. It penalizes the discriminator if its gradients with respect to the interpolated samples deviate from the norm of 1. This helps to prevent the discriminator from becoming too powerful and improves the overall training stability.\n",
        "\n",
        "### Lipschitz Constraint\n",
        "\n",
        "The Lipschitz constraint is a mathematical property that ensures the discriminator's function is not too sensitive to small changes in the input. In the context of GANs, enforcing the Lipschitz constraint helps prevent mode collapse and improves the overall quality of the generated samples.\n",
        "\n",
        "## Code Structure\n",
        "\n",
        "The compute_gradient_penalty function takes three parameters:\n",
        "\n",
        "* discriminator: The discriminator model used in the GAN.\n",
        "* real_samples: The batch of real samples used for training.\n",
        "* fake_samples: The batch of generated (fake) samples produced by the generator.\n",
        "\n",
        "The function calculates the gradient penalty loss for the Wasserstein GAN with gradient penalty and returns the computed gradient penalty.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "The compute_gradient_penalty function plays a crucial role in training the Wasserstein GAN with gradient penalty. It calculates the gradient penalty loss, which helps to enforce the Lipschitz constraint on the discriminator and improve the stability and convergence of the GAN training process. By penalizing deviations from a unit norm in the gradients of the discriminator's output with respect to the interpolated samples, the model is encouraged to have a smooth decision boundary and improve the overall stability and convergence of the training process.\n",
        "\n",
        "\n",
        "[^1]: https://zzzcode.ai/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CUDA\n",
        "\n",
        "How to use t4 GPU in Google Colab\n",
        "\n",
        "https://medium.com/analytics-vidhya/ml06-893e4cb389c6"
      ],
      "metadata": {
        "id": "GrLoJcvdpT3b"
      },
      "id": "GrLoJcvdpT3b"
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8I_ZUpgm2xs",
        "outputId": "39e8b07c-53ea-4ef7-f3bb-9013c07b5208"
      },
      "id": "v8I_ZUpgm2xs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XC28YSDxnHtx",
        "outputId": "d46e5fdc-bab7-4ea0-c238-9f10a342bbd9"
      },
      "id": "XC28YSDxnHtx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Oct 15 13:52:57 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8     9W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.ones(3,2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3P4z6HBrnUmt",
        "outputId": "9d6c757b-53b4-4a8a-c721-bb7024978f85"
      },
      "id": "3P4z6HBrnUmt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /etc/*-release"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydU0bFE6lznJ",
        "outputId": "417bb62d-07d2-4916-f1ea-0f8630aec805"
      },
      "id": "ydU0bFE6lznJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DISTRIB_ID=Ubuntu\n",
            "DISTRIB_RELEASE=22.04\n",
            "DISTRIB_CODENAME=jammy\n",
            "DISTRIB_DESCRIPTION=\"Ubuntu 22.04.2 LTS\"\n",
            "PRETTY_NAME=\"Ubuntu 22.04.2 LTS\"\n",
            "NAME=\"Ubuntu\"\n",
            "VERSION_ID=\"22.04\"\n",
            "VERSION=\"22.04.2 LTS (Jammy Jellyfish)\"\n",
            "VERSION_CODENAME=jammy\n",
            "ID=ubuntu\n",
            "ID_LIKE=debian\n",
            "HOME_URL=\"https://www.ubuntu.com/\"\n",
            "SUPPORT_URL=\"https://help.ubuntu.com/\"\n",
            "BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\n",
            "PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\n",
            "UBUNTU_CODENAME=jammy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "2fHOaBo9rRlm"
      },
      "id": "2fHOaBo9rRlm"
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip file.zip # zip them, upload, then unzip it."
      ],
      "metadata": {
        "id": "pAfGjsKgrUuf"
      },
      "id": "pAfGjsKgrUuf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GANs model"
      ],
      "metadata": {
        "id": "WfuRiVu7pjS_"
      },
      "id": "WfuRiVu7pjS_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee7b1c52",
      "metadata": {
        "id": "ee7b1c52"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable, grad\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a505ebc",
      "metadata": {
        "id": "6a505ebc"
      },
      "outputs": [],
      "source": [
        "# Functions: Gradient Penalty Function, Encode Label, Decode Target\n",
        "\n",
        "def compute_gradient_penalty(discriminator, real_samples, fake_samples):\n",
        "\n",
        "    \"\"\"Calculates the gradient penalty loss for the Wasserstein GAN with gradient penalty.\"\"\"\n",
        "\n",
        "    # Generate random interpolation\n",
        "\n",
        "    \"\"\"\n",
        "    In this step, a random interpolation factor alpha is generated using the torch.rand function.\n",
        "    This step creates a smooth transition between the real and fake samples.\n",
        "    The interpolation is calculated as\n",
        "    \"\"\"\n",
        "\n",
        "    alpha = torch.rand(real_samples.size(0), 1, 1, 1, dtype=torch.float32, requires_grad=True)\n",
        "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples))\n",
        "\n",
        "    # Calculate Discriminator Output for Interpolated Samples\n",
        "\n",
        "    \"\"\"\n",
        "    The interpolated samples are then passed through the discriminator model\n",
        "    to obtain the discriminator output for each sample.\n",
        "    \"\"\"\n",
        "\n",
        "    d_interpolates = discriminator(interpolates)\n",
        "\n",
        "    # Create fake labels\n",
        "\n",
        "    \"\"\"\n",
        "    A tensor of fake labels is created using the torch.full function.\n",
        "    These labels are set to 1.0 and have the same shape as the real samples.\n",
        "    It is used as the grad_outputs argument in the grad function,\n",
        "    which calculates the gradients of d_interpolates with respect to interpolates.\n",
        "    \"\"\"\n",
        "\n",
        "    fake = torch.full((real_samples.shape[0], 1), 1.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "    # Calculate gradients w.r.t. interpolates\n",
        "\n",
        "    \"\"\"\n",
        "    The gradients of the discriminator outputs with respect to the interpolated samples are calculated using the grad function from the torch.autograd module.\n",
        "    The create_graph=True and retain_graph=True arguments ensure that the gradients can be used to compute higher-order gradients if needed.\n",
        "    \"\"\"\n",
        "\n",
        "    gradients = grad(outputs=d_interpolates, inputs=interpolates, grad_outputs=fake,\n",
        "                     create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
        "\n",
        "    # Reshape and calculate norm\n",
        "\n",
        "    \"\"\"\n",
        "    The gradients are reshaped to have a size of (batch_size, num_features) using the view method.\n",
        "    Then, the norm of the gradients along the second dimension (dim=1) (across the features) is calculated\n",
        "    using the norm method with p=2.\n",
        "    The result is subtracted by 1 and squared to enforce the Lipschitz constraint.\n",
        "    Finally, the squared norm minus 1 is averaged across the batch to obtain the gradient penalty.\n",
        "\n",
        "    \"\"\"\n",
        "    gradients = gradients.view(gradients.size(0), -1)\n",
        "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
        "\n",
        "    return gradient_penalty\n",
        "\n",
        "\n",
        "def encode_label(label):\n",
        "    target = torch.zeros(6)\n",
        "    for l in str(label).split(\" \"):\n",
        "        target[int(l)] = 1.\n",
        "    return target\n",
        "\n",
        "\n",
        "def decode_target(target, text_labels=False, threshold=0.5):\n",
        "    result = []\n",
        "    for i, x in enumerate(target):\n",
        "        if (x >= threshold):\n",
        "            if text_labels:\n",
        "                result.append(labels[i] + \"(\" + str(i) + \")\")\n",
        "            else:\n",
        "                result.append(str(i))\n",
        "    return \" \".join(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9746878",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9746878",
        "outputId": "075b8f23-9169-4135-b858-a677ead3ffa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "# %% CUDA switch\n",
        "\"\"\"traditional Wasserstein GAN suffering from exploding and vanishing gradients\n",
        "due to interactions between the weight constraints and the cost function,\n",
        " which can only be remedied by a carefully chosen clipping threshold.\"\"\"\n",
        "\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "\n",
        "print(cuda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ef09ffc",
      "metadata": {
        "id": "3ef09ffc"
      },
      "outputs": [],
      "source": [
        "# %% Case and Image Shape\n",
        "cases = [\"Normal min-max\", \"Wasserstein loss\", \"Wasserstein with Gradient\"]\n",
        "case = cases[2]\n",
        "img_shape = (3, 32, 32)  # NOTE: (image_channel, image_size, image_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71e10553",
      "metadata": {
        "id": "71e10553"
      },
      "outputs": [],
      "source": [
        "# %% Generator\n",
        "\"\"\"Captures the data distribution\"\"\"\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        # Define the neural network\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(100, 128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.BatchNorm1d(256, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.BatchNorm1d(512, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.BatchNorm1d(1024, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(1024, int(np.prod(img_shape))),  # 32*32 = 1024\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        img = self.model(z)\n",
        "        img = img.view(img.size(0), *img_shape)  # TODO: What is *image_shape\n",
        "        return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0eb8fc13",
      "metadata": {
        "id": "0eb8fc13"
      },
      "outputs": [],
      "source": [
        "# %% Discriminator\n",
        "\"\"\" Estimates the probability that a sample came from the training data rather than Generator\"\"\"\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        # Define the model\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(int(np.prod(img_shape)), 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        img_flat = img.view(img.size(0), -1)\n",
        "        validity = self.model(img_flat)\n",
        "        return validity"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess unconditione GANs"
      ],
      "metadata": {
        "id": "xEyv5jPXppWh"
      },
      "id": "xEyv5jPXppWh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f748cddd",
      "metadata": {
        "id": "f748cddd"
      },
      "outputs": [],
      "source": [
        "# %% Move Generator model, Discriminator Model to Cuda, FLoatTensor\n",
        "\"\"\" Generator tries to min the adversarial loss,\n",
        "    the discriminator also\"\"\"\n",
        "generator = Generator()\n",
        "if cuda:\n",
        "    generator.cuda()\n",
        "\n",
        "discriminator = Discriminator()\n",
        "if cuda:\n",
        "    discriminator.cuda()\n",
        "\n",
        "Tensor = torch.cuda.FloatStorage if cuda else torch.FloatTensor\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b83bc31c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "b83bc31c",
        "outputId": "8c6ff321-cab7-4e41-b0a9-27e66441ac47"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-88c5a2c137b5>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mROOT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPATH_TO_DATASETS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/datasets/image_classification/seg_part/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mbuildings_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mROOT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mis_valid_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     ):\n\u001b[0;32m--> 309\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    142\u001b[0m     ) -> None:\n\u001b[1;32m    143\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \"\"\"\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \"\"\"\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Volumes/SGB256/PycharmProjects/ISML/datasets/image_classification/seg_part/'"
          ]
        }
      ],
      "source": [
        "# %% Unconditioned: Create a directory for the sample images\n",
        "if case == cases[0]:\n",
        "    os.makedirs(\"images/gan_uncond_images\", exist_ok=True)\n",
        "elif case == cases[1]:\n",
        "    os.makedirs(\"images/wgan_uncond_images\", exist_ok=True)\n",
        "elif case == cases[2]:\n",
        "    os.makedirs(\"images/wgan_gp_uncond_images\", exist_ok=True)\n",
        "\n",
        "# NOTE: Keep the size to 32x32 to make it amenable the hardware\n",
        "transform_ds = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])\n",
        "\n",
        "# %% Unconditioned: Dataset, Batch Size, Epochs, Dataloader, Image Shape\n",
        "PATH_TO_DATASETS = \"/Volumes/SGB256/PycharmProjects/ISML\"\n",
        "ROOT = PATH_TO_DATASETS + \"/datasets/image_classification/seg_part/\"\n",
        "\n",
        "buildings_dataset = torchvision.datasets.ImageFolder(root=ROOT, transform=transform_ds)\n",
        "\n",
        "batch_size = 512\n",
        "num_epochs = 1000\n",
        "buildings_dataloader = DataLoader(buildings_dataset, batch_size, shuffle=True, num_workers=0, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a5ce224",
      "metadata": {
        "id": "2a5ce224"
      },
      "outputs": [],
      "source": [
        "# %% Unconditioned: Initialize Optimizer and create\n",
        "if case == cases[0]:\n",
        "    adversarial_loss = torch.nn.BCELoss()  # Binary Cross Entropy Loss\n",
        "    if cuda:\n",
        "        adversarial_loss.cuda()\n",
        "    optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))  # TODO: what do betas?\n",
        "    optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "elif case == cases[1]:\n",
        "    optimizer_G = torch.optim.RMSprop(generator.parameters(), lr=0.00005)\n",
        "    optimizer_D = torch.optim.RMSprop(discriminator.parameters(), lr=0.00005)\n",
        "elif case == cases[2]:\n",
        "    optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "    optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train unconditioned GANs"
      ],
      "metadata": {
        "id": "h_qB4bLepuJJ"
      },
      "id": "h_qB4bLepuJJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e017e78a",
      "metadata": {
        "id": "e017e78a"
      },
      "outputs": [],
      "source": [
        "# %% Unconditioned: Loop\n",
        "if case == cases[0]:\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (imgs, _) in enumerate(buildings_dataloader):\n",
        "\n",
        "            # Adversarial ground truths\n",
        "            valid = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)  # TODO: What happens here?\n",
        "            fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)\n",
        "\n",
        "            # Create variable for the inputs    TODO: What does .type(Tensor)\n",
        "            real_imgs = Variable(imgs.type(Tensor))\n",
        "\n",
        "            # Generator training begins here\n",
        "            optimizer_G.zero_grad()\n",
        "\n",
        "            # Sample random noise as input  TODO: What is this noise?\n",
        "            z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0],\n",
        "                                                        100))))  # NOTE: `100` is the size of the latent dimensionality of the model, adjusting it can have huge effects on the training dynamics\n",
        "\n",
        "            # Generate images\n",
        "            fake_imgs = generator(z)\n",
        "\n",
        "            # Take the loss\n",
        "            g_loss = adversarial_loss(discriminator(fake_imgs), valid)\n",
        "            g_loss.backward()  # Gradient of loss wrt parameters\n",
        "            optimizer_G.step()  # Optimizes parameters\n",
        "\n",
        "            # Discriminator training begins here\n",
        "            optimizer_D.zero_grad()\n",
        "\n",
        "            # Assess the discriminators classification ability\n",
        "            real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
        "            fake_loss = adversarial_loss(discriminator(fake_imgs.detach()), fake)\n",
        "\n",
        "            # Loss of the discriminator\n",
        "            d_loss = (real_loss + fake_loss) / 2\n",
        "            d_loss.backward()\n",
        "            optimizer_D.step()\n",
        "\n",
        "            print(\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\" %\n",
        "                  (epoch, num_epochs, i, len(buildings_dataloader), d_loss.item(), g_loss.item()))\n",
        "\n",
        "            batches_done = epoch * len(buildings_dataloader) + i\n",
        "            if batches_done % 400 == 0:\n",
        "                save_image(fake_imgs.data[:25], \"images/gan_uncond_images/%d.png\" % batches_done, nrow=5,\n",
        "                           normalize=True)\n",
        "elif case == cases[1]:\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (imgs, _) in enumerate(buildings_dataloader):\n",
        "\n",
        "            # Create a variable for the inputs\n",
        "            real_imgs = Variable(imgs.type(Tensor))\n",
        "\n",
        "            # Begin with the discriminator training here\n",
        "            optimizer_D.zero_grad()\n",
        "\n",
        "            z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0],\n",
        "                                                        100))))  # NOTE: `100` is the size of the latent dimensionality of the model, adjusting it can have huge effects on the training dynamics\n",
        "\n",
        "            fake_imgs = generator(z).detach()\n",
        "            d_loss = -torch.mean(discriminator(real_imgs)) + torch.mean(discriminator(fake_imgs))\n",
        "            d_loss.backward()\n",
        "\n",
        "            optimizer_D.step()\n",
        "\n",
        "            # Clip weights of the discriminator at the end of the iteration\n",
        "            for p in discriminator.parameters():\n",
        "                p.data.clamp_(-0.01, 0.01)\n",
        "\n",
        "            # Train the generator only every fifth iteration\n",
        "            if i % 5 == 0:\n",
        "                optimizer_G.zero_grad()\n",
        "\n",
        "                gen_imgs = generator(z)\n",
        "                g_loss = -torch.mean(discriminator(gen_imgs))\n",
        "                g_loss.backward()\n",
        "                optimizer_G.step()\n",
        "\n",
        "                print( \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
        "                    % (epoch, num_epochs, i, len(buildings_dataloader), d_loss.item(), g_loss.item()))\n",
        "\n",
        "        batches_done = epoch * len(buildings_dataloader) + i\n",
        "        if batches_done % 400 == 0:\n",
        "            save_image(gen_imgs.data[:25], \"images/wgan_uncond_images/%d.png\" % batches_done, nrow=5, normalize=True)\n",
        "\n",
        "elif case == cases[2]:\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (imgs, _) in enumerate(buildings_dataloader):\n",
        "\n",
        "            # Create a variable for the inputs\n",
        "            real_imgs = Variable(imgs.type(Tensor), requires_grad=True)\n",
        "\n",
        "            # Begin with the discriminator training here\n",
        "            optimizer_D.zero_grad()\n",
        "\n",
        "            # NOTE: `100` is the size of the latent dimensionality of the model, adjusting it can have huge effects on the training dynamics\n",
        "            z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], 100))))\n",
        "            fake_imgs = generator(z).detach()\n",
        "            gradient_penalty = compute_gradient_penalty(discriminator, real_imgs.data, fake_imgs.data)\n",
        "            d_loss = -torch.mean(discriminator(real_imgs)) + torch.mean(\n",
        "                discriminator(fake_imgs)) + 10 * gradient_penalty\n",
        "            d_loss.backward()\n",
        "            optimizer_D.step()\n",
        "\n",
        "            # Clip weights of the discriminator at the end of the iteration\n",
        "            for p in discriminator.parameters():\n",
        "                p.data.clamp_(-0.01, 0.01)\n",
        "\n",
        "            # Train the generator only every fifth iteration\n",
        "            if i % 5 == 0:\n",
        "                optimizer_G.zero_grad()\n",
        "\n",
        "                gen_imgs = generator(z)\n",
        "                g_loss = -torch.mean(discriminator(gen_imgs))\n",
        "                g_loss.backward()\n",
        "                optimizer_G.step()\n",
        "\n",
        "                print(\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
        "                      % (epoch, num_epochs, i, len(buildings_dataloader), d_loss.item(), g_loss.item()))\n",
        "            batches_done = epoch * len(buildings_dataloader) + i\n",
        "            if batches_done % 400 == 0:\n",
        "                save_image(gen_imgs.data[:25],\n",
        "                           \"images/wgan_gp_uncond_images/%d.png\" % batches_done,\n",
        "                           nrow=5, normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess conditioned GAN"
      ],
      "metadata": {
        "id": "0ExLRhNTpxIF"
      },
      "id": "0ExLRhNTpxIF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e62ef1e",
      "metadata": {
        "id": "2e62ef1e"
      },
      "outputs": [],
      "source": [
        "# %% Conditional GANs: Labels\n",
        "\n",
        "labels = {\n",
        "    0: \"buildings\",\n",
        "    1: \"forest\",\n",
        "    2: \"glaciers\",\n",
        "    3: \"mountain\",\n",
        "    4: \"sea\",\n",
        "    5: \"street\"\n",
        "}\n",
        "\n",
        "# %% Conditional GANs: Transforms TODO: Why two different transforms?\n",
        "transform_ds = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])\n",
        "\n",
        "transform_dt = transforms.Compose([transforms.ToTensor(), transforms.Normalize([.5, .5, .5], [.5, .5, .5])])\n",
        "\n",
        "# %% Conditional GANs: Whole Dataset; Train + Test\n",
        "\n",
        "ROOT = PATH_TO_DATASETS + \"/datasets/image_classification/seg_train\"\n",
        "dataset = torchvision.datasets.ImageFolder(root=ROOT, transform=transform_ds)\n",
        "\n",
        "ROOT = PATH_TO_DATASETS + \"/datasets/image_classification/seg_test\"\n",
        "test_dataset = torchvision.datasets.ImageFolder(root=ROOT, transform=transform_dt)\n",
        "\n",
        "# %% Conditional GANs: Batch Size, Epochs, Dataloader\n",
        "batch_size = 512\n",
        "\n",
        "# Define the length of the training for the conditional GANs\n",
        "num_epochs = 1000\n",
        "\n",
        "# Define the dataloader\n",
        "whole_dataloader = DataLoader(dataset, batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
        "\n",
        "# %% Conditional GANs: Create a directory for the sample images\n",
        "if case == cases[0]:\n",
        "    os.makedirs(\"images/gan_cond_images\", exist_ok=True)\n",
        "elif case == cases[1]:\n",
        "    os.makedirs(\"images/wgan_cond_images\", exist_ok=True)\n",
        "elif case == cases[2]:\n",
        "    os.makedirs(\"images/wgan_gp_cond_images\", exist_ok=True)\n",
        "\n",
        "# %% Conditional GANs: Initialize optimizer\n",
        "if case == cases[0]:\n",
        "    adversarial_loss = torch.nn.BCELoss()\n",
        "\n",
        "    if cuda:\n",
        "        adversarial_loss.cuda()\n",
        "\n",
        "    optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "    optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "elif case == cases[1]:\n",
        "    optimizer_G = torch.optim.RMSprop(generator.parameters(), lr=0.00005)\n",
        "    optimizer_D = torch.optim.RMSprop(discriminator.parameters(), lr=0.00005)\n",
        "elif case == cases[2]:\n",
        "    optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "    optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train conditioned GANs"
      ],
      "metadata": {
        "id": "O05lO_btp3as"
      },
      "id": "O05lO_btp3as"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a146bb06",
      "metadata": {
        "id": "a146bb06"
      },
      "outputs": [],
      "source": [
        "# %% Conditional GANs: Loop\n",
        "if case == cases[0]:\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (imgs, labels) in enumerate(whole_dataloader):\n",
        "\n",
        "            # Normalize and reshape the labels\n",
        "            labels = (1 / max(labels)) * labels\n",
        "            labels = labels.view(imgs.shape[0],\n",
        "                                 1)  # NOTE: This is required for the later concatenation [imgs.shape[0]] -> [imgs.shape[0], 1]\n",
        "\n",
        "            # Adversarial ground truths\n",
        "            valid = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)\n",
        "            fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)\n",
        "\n",
        "            # Create variable for the inputs\n",
        "            real_imgs = Variable(imgs.type(Tensor))\n",
        "\n",
        "            # Generator training begins here\n",
        "            optimizer_G.zero_grad()\n",
        "\n",
        "            # Sample random noise as input and conditon with labels\n",
        "            z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], 100 - 1))))\n",
        "            z_cond = torch.cat((z, labels), dim=1)\n",
        "\n",
        "            # Generate images\n",
        "            fake_imgs = generator(z_cond)\n",
        "\n",
        "            # Take the loss\n",
        "            g_loss = adversarial_loss(discriminator(fake_imgs), valid)\n",
        "            g_loss.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "            # Discriminator training begins here\n",
        "            optimizer_D.zero_grad()\n",
        "\n",
        "            # Assess the discriminators classification ability\n",
        "            real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
        "            fake_loss = adversarial_loss(discriminator(fake_imgs.detach()), fake)\n",
        "\n",
        "            # Loss of the discriminator\n",
        "            d_loss = (real_loss + fake_loss) / 2\n",
        "            d_loss.backward()\n",
        "            optimizer_D.step()\n",
        "\n",
        "            print(\n",
        "                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
        "                % (epoch, num_epochs, i, len(whole_dataloader), d_loss.item(), g_loss.item())\n",
        "            )\n",
        "\n",
        "            batches_done = epoch * len(whole_dataloader) + i\n",
        "            if batches_done % 400 == 0:\n",
        "                save_image(fake_imgs.data[:25], \"images/gan_cond_images/%d.png\" % batches_done, nrow=5, normalize=True)\n",
        "\n",
        "elif case == cases[1]:\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (imgs, labels) in enumerate(whole_dataloader):\n",
        "\n",
        "            # Normalize and reshape the labels\n",
        "            labels = (1 / max(labels)) * labels\n",
        "            labels = labels.view(imgs.shape[0],\n",
        "                                 1)  # NOTE: This is required for the later concatenation [imgs.shape[0]] -> [imgs.shape[0], 1]\n",
        "\n",
        "            # Adversarial ground truths\n",
        "            valid = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)\n",
        "            fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)\n",
        "\n",
        "            # Create variable for the inputs\n",
        "            real_imgs = Variable(imgs.type(Tensor))\n",
        "\n",
        "            # Discriminator training begins here\n",
        "            optimizer_D.zero_grad()\n",
        "\n",
        "            # Sample random noise as input and conditon with labels\n",
        "            z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], 100 - 1))))\n",
        "            z_cond = torch.cat((z, labels), dim=1)\n",
        "\n",
        "            # Generate images\n",
        "            fake_imgs = generator(z_cond).detach()\n",
        "\n",
        "            # Take the loss\n",
        "            d_loss = -torch.mean(discriminator(real_imgs)) + torch.mean(discriminator(fake_imgs))\n",
        "            d_loss.backward()\n",
        "\n",
        "            optimizer_D.step()\n",
        "\n",
        "            # Clip weights of the discriminator at the end of the iteration\n",
        "            for p in discriminator.parameters():\n",
        "                p.data.clamp_(-0.01, 0.01)\n",
        "\n",
        "            # Train the generator only every fifth iteration\n",
        "            if i % 5 == 0:\n",
        "                optimizer_G.zero_grad()\n",
        "\n",
        "                gen_imgs = generator(z_cond)\n",
        "                g_loss = -torch.mean(discriminator(gen_imgs))\n",
        "                g_loss.backward()\n",
        "                optimizer_G.step()\n",
        "\n",
        "            print(\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
        "                  % (epoch, num_epochs, i, len(whole_dataloader), d_loss.item(), g_loss.item()))\n",
        "\n",
        "            batches_done = epoch * len(whole_dataloader) + i\n",
        "            if batches_done % 400 == 0:\n",
        "                save_image(fake_imgs.data[:25], \"images/gan_cond_images/%d.png\" % batches_done, nrow=5, normalize=True)\n",
        "\n",
        "elif case == cases[2]:\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (imgs, labels) in enumerate(whole_dataloader):\n",
        "\n",
        "            # Normalize and reshape the labels\n",
        "            labels = (1 / max(labels)) * labels\n",
        "            labels = labels.view(imgs.shape[0],\n",
        "                                 1)  # NOTE: This is required for the later concatenation [imgs.shape[0]] -> [imgs.shape[0], 1]\n",
        "\n",
        "            # Adversarial ground truths\n",
        "            valid = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)\n",
        "            fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)\n",
        "\n",
        "            # Create variable for the inputs\n",
        "            real_imgs = Variable(imgs.type(Tensor))\n",
        "\n",
        "            # Generator training begins here\n",
        "            optimizer_G.zero_grad()\n",
        "\n",
        "            # Sample random noise as input and conditon with labels\n",
        "            z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], 100 - 1))))\n",
        "            z_cond = torch.cat((z, labels), dim=1)\n",
        "\n",
        "            # Generate images\n",
        "            fake_imgs = generator(z_cond).detach()\n",
        "\n",
        "            # Take the loss\n",
        "            gradient_penalty = compute_gradient_penalty(discriminator, real_imgs.data, fake_imgs.data)\n",
        "            d_loss = -torch.mean(discriminator(real_imgs)) + torch.mean(discriminator(fake_imgs)) \\\n",
        "                     + 10 * gradient_penalty\n",
        "\n",
        "            d_loss.backward()\n",
        "            optimizer_D.step()\n",
        "\n",
        "            # Clip weights of the discriminator at the end of the iteration\n",
        "            for p in discriminator.parameters():\n",
        "                p.data.clamp_(-0.01, 0.01)\n",
        "\n",
        "            # Train the generator only every fifth iteration\n",
        "            if i % 5 == 0:\n",
        "                optimizer_G.zero_grad()\n",
        "\n",
        "                gen_imgs = generator(z_cond)\n",
        "                g_loss = -torch.mean(discriminator(gen_imgs))\n",
        "                g_loss.backward()\n",
        "                optimizer_G.step()\n",
        "\n",
        "            print(\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
        "                  % (epoch, num_epochs, i, len(whole_dataloader), d_loss.item(), g_loss.item()))\n",
        "\n",
        "            batches_done = epoch * len(whole_dataloader) + i\n",
        "            if batches_done % 400 == 0:\n",
        "                save_image(fake_imgs.data[:25], \"images/gan_cond_images/%d.png\" % batches_done, nrow=5, normalize=True)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}